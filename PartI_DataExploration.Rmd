---
title: "Part I: Data Exploration and Prediction"
output: html_notebook
---

First, we load packages:
```{r}
library(readxl)
library(tidyverse)
library(dplyr)
library(ggplot2)
library("GGally")
library(corrplot)
library(cvTools)
library(glmnet)
library(plotmo)
library(pROC)
library(tibble)
library(modelr)
library(repr)
library(knitr)
library(stargazer)
library(ROCR)
```

Then, we load the data:
```{r}
school_demographics <- read_excel("Data/cupc1718-k12.xlsx", sheet = "School-Level CALPADS UPC Data", skip = 1)
Pb_SchoolDistricts <- read.csv("Data/Hg_SchoolDistricts.csv")

```

Next, we clean the column names:
```{r}
colnames(school_demographics) <- gsub(" ", "_", colnames(school_demographics))
colnames(Pb_SchoolDistricts) <- gsub(" ", "_", colnames(Pb_SchoolDistricts))

colnames(school_demographics) <- tolower(colnames(school_demographics))
colnames(Pb_SchoolDistricts) <- tolower(colnames(Pb_SchoolDistricts))

colnames(school_demographics) <- gsub("\r\n", "", colnames(school_demographics))
colnames(Pb_SchoolDistricts) <- gsub("\r\n", "", colnames(Pb_SchoolDistricts))

colnames(school_demographics) <- gsub("&", "", colnames(school_demographics))
colnames(Pb_SchoolDistricts) <- gsub("&", "", colnames(Pb_SchoolDistricts))

colnames(school_demographics) <- gsub("_(y/n)", "", colnames(school_demographics), fixed=TRUE)

colnames(school_demographics) <- gsub("_(el)", "", colnames(school_demographics), fixed=TRUE)

colnames(school_demographics) <- gsub("_(upc)", "", colnames(school_demographics), fixed=TRUE)

colnames(school_demographics) <- gsub("(upc)", "", colnames(school_demographics), fixed=TRUE)

```


Then, we merge the datasets for school demographics and school lead levels by school name and county:
```{r}
combined_data <- merge(school_demographics, Pb_SchoolDistricts, by.x=c("school_name", "county_name"), by.y = c("school_name", "school_county")) 

```

Then, we clean the combined dataset:
```{r}
#select column names according to google doc

drops <- c("academic_year", "county_code", "district_code", "school_code", "charter_number", "irc", "low_grade", "high_grade", "unduplicated", "calpads_fall_1", "pscode", "district", "school_address", "school_site_name", "xmod", "rpt_unit", "water_system_county", "samp_date", "sample_loaddate", "samp_loaded", "samp_time", "pws_id")

combined_data_clean <- combined_data[ , !(names(combined_data) %in% drops)]

#remove resampled observations
combined_data_clean$ale_follow_up_action <- combined_data_clean$ale_follow_up_action %>% replace_na('NA')
combined_data_clean <- combined_data_clean[!(combined_data_clean$ale_follow_up_action == "Resampled"),]
combined_data_clean <- combined_data_clean[!(combined_data_clean$ale_follow_up_action == "Resampled (Incorrect initial sampling method)"),]
combined_data_clean <- combined_data_clean[!(combined_data_clean$ale_follow_up_action == "Initial Sample Incorrectly Sampled"),]
combined_data_clean <- combined_data_clean[!(combined_data_clean$ale_follow_up_action == "Incorrect initial sample, not drinking water location"),]
combined_data_clean <- combined_data_clean[!(combined_data_clean$ale_follow_up_action == "Resamped"),]
combined_data_clean <- combined_data_clean[!(combined_data_clean$ale_follow_up_action == "Resampled, Incorrect Initial Sampling"),]

#remove charter schools with funding type na
combined_data_clean <- combined_data_clean[!(combined_data_clean$"charter_school" == "Yes" & combined_data_clean$charter_funding_type == "N/A"),]

#remove data with NAs in the columns: total enrollment, frmp, homeless, migrant, direct certification, undup, el, results, action level exceedence, school_type
combined_data_clean %>% drop_na("total_enrollment", "free_reducedmealprogram", "homeless", "migrantprogram", "direct_certification", "unduplicatedfrpm_eligible_count", "english_learner" , "result", "action_level_exceedance", "school_type.y")

#combine multiple samples by taking max samples when multiple samples taken at a school
combined_data_clean_grouped <- combined_data_clean %>% 
  group_by(school_name, county_name) %>% 
  mutate(result.max= max(result))

combined_data_clean_grouped <-subset(combined_data_clean_grouped, result==result.max)
combined_data_clean_grouped <- unique(combined_data_clean_grouped)

#convert exceedence to binary variable (0,1)
combined_data_clean_grouped$action_level_exceedance <- ifelse(combined_data_clean_grouped$action_level_exceedance=="Yes",1,0)

#remove data with NAs in the columns: total enrollment, frmp, homeless, migrant, direct certification, undup, el, results, action level exceedence, school_type
combined_data_clean_grouped = combined_data_clean_grouped[,!(names(combined_data_clean_grouped) =='result')]
combined_data_clean_grouped_rmna <- combined_data_clean_grouped %>% 
 drop_na(total_enrollment)  %>%
 drop_na(homeless)  %>%
 drop_na(migrantprogram)  %>%
 drop_na(direct_certification)  %>%
 drop_na(unduplicatedfrpm_eligible_count)  %>%
 drop_na(english_learner)  %>%
 drop_na(result.max)  %>%
 drop_na(action_level_exceedance)  %>%
 drop_na(school_type.y)

```


Next, we convert our covariates to ratios so that they are not biased by the total enrollment:
```{r}
print(colnames(combined_data_clean_grouped_rmna))
combined_data_clean_grouped_rmna$free_reducedmealprogram =  combined_data_clean_grouped_rmna$free_reducedmealprogram/combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$foster =  combined_data_clean_grouped_rmna$foster/combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$homeless =  combined_data_clean_grouped_rmna$homeless/combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$migrantprogram =  combined_data_clean_grouped_rmna$migrantprogram/combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$direct_certification =  combined_data_clean_grouped_rmna$direct_certification/combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$unduplicatedfrpm_eligible_count=  combined_data_clean_grouped_rmna$unduplicatedfrpm_eligible_count/combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$english_learner =  combined_data_clean_grouped_rmna$english_learner /combined_data_clean_grouped_rmna$total_enrollment

combined_data_clean_grouped_rmna$calpads_unduplicated_pupil_count =  combined_data_clean_grouped_rmna$calpads_unduplicated_pupil_count /combined_data_clean_grouped_rmna$total_enrollment
  
```

We make adjustments to combine school type categories with small populations:
```{r}
combined_data_clean_grouped_rmna <- combined_data_clean_grouped_rmna %>%
  rename(school_type = school_type.x)

high_columns <- c("High Schools (Public)", "High Schools In 1 School Dist. (Public)")
middle_columns <- c("Intermediate/Middle Schools (Public)", "Junior High Schools (Public)")
elem_columns <- c("Elemen Schools In 1 School Dist. (Public)", "Elementary Schools (Public)")
other_columns <- c("Alternative Schools of Choice", "Continuation High Schools", "District Community Day Schools", "K-12 Schools (Public)", "Opportunity Schools", "Preschool", "County Community", "Special Education Schools (Public)", "Juvenile Court Schools")

combined_data_clean_grouped_rmna$school_type[combined_data_clean_grouped_rmna$school_type %in% high_columns] <- "High"
combined_data_clean_grouped_rmna$school_type[combined_data_clean_grouped_rmna$school_type %in% middle_columns] <- "Middle"
combined_data_clean_grouped_rmna$school_type[combined_data_clean_grouped_rmna$school_type %in% elem_columns] <- "Elem"
combined_data_clean_grouped_rmna$school_type[combined_data_clean_grouped_rmna$school_type %in% other_columns] <- "Other"

has_provisions <- c("Provision 3", "Provision 2", "Provision 1", "CEP", "Breakfast Provision 2", "Lunch Provision 2")
combined_data_clean_grouped_rmna$nslp_provision_status[combined_data_clean_grouped_rmna$nslp_provision_status %in% has_provisions] <- "Provisions"
```


We allocate our training and test sets:
```{r}
#calculate the number of observations that should be in our training set
size_training = round(.8*nrow(combined_data_clean_grouped_rmna), digits = 0)

#allocate training and test data
in.train = sample(nrow(combined_data_clean_grouped_rmna), size = size_training)
train = combined_data_clean_grouped_rmna[in.train, ]
test = combined_data_clean_grouped_rmna[-in.train, ]

```


We generate density plots for each continuous covariate in our training data set:

```{r}
cont.colnames <- train %>% select_if(is.numeric) %>% colnames()
fact.colnames <- train %>% select_if(negate(is.numeric)) %>% colnames()
print(cont.colnames)

ggplot(data=train)+
  geom_density(aes(free_reducedmealprogram))

ggplot(data=train)+
  geom_density(aes(foster))

ggplot(data=train)+
  geom_density(aes(homeless))

ggplot(data=train)+
  geom_density(aes(migrantprogram))

ggplot(data=train)+
  geom_density(aes(direct_certification))

ggplot(data=train)+
  geom_density(aes(unduplicatedfrpm_eligible_count))

ggplot(data=train)+
  geom_density(aes(english_learner))

ggplot(data=train)+
  geom_density(aes(calpads_unduplicated_pupil_count))

ggplot(data=train)+
  geom_density(aes(result.max))

ggplot(data=train)+
  geom_density(aes(log(result.max)))
```

And barplots for each discrete variable:
```{r}
print(cont.colnames)

ggplot(data=train)+
  geom_bar(aes(district_type))+ theme(axis.text.x = element_text(angle = 45, hjust=1))

ggplot(data=train)+
  geom_bar(aes(school_type))+ theme(axis.text.x = element_text(angle = 45, hjust=1))

ggplot(data=train)+
  geom_bar(aes(educational_option_type))+ theme(axis.text.x = element_text(angle = 45, hjust=1))

ggplot(data=train)+
  geom_bar(aes(nslp_provision_status))

ggplot(data=train)+
  geom_bar(aes(charter_funding_type))

ggplot(data=train)+
  geom_bar(aes(school_type.y))

ggplot(data=train)+
  geom_bar(aes(action_level_exceedance))

ggplot(data=train)+
  geom_bar(aes(charter_school))

```

We group the distribution of results by the value of a factor:
```{r}
ggplot(data=train)+
  geom_violin(aes(x=district_type, y=log(result.max)))+ theme(axis.text.x = element_text(angle = 45, hjust=1))

ggplot(data=train)+
  geom_violin(aes(x=school_type, y=log(result.max)))+ theme(axis.text.x = element_text(angle = 45, hjust=1))
  
ggplot(data=train)+
  geom_violin(aes(x=educational_option_type, y=log(result.max)))+ theme(axis.text.x = element_text(angle = 45, hjust=1))

ggplot(data=train)+
  geom_violin(aes(x=nslp_provision_status, y=log(result.max)))+ theme(axis.text.x = element_text(angle = 45, hjust=1))

ggplot(data=train)+
  geom_violin(aes(x=charter_funding_type, y=log(result.max)))+ theme(axis.text.x = element_text(angle = 45, hjust=1))


ggplot(data=train)+
  geom_violin(aes(x=charter_school, y=log(result.max)))+ theme(axis.text.x = element_text(angle = 45, hjust=1))


```


We create a scatterplot and correlation plot for continuous variables:

```{r}
train.num <- train %>% select_if(is.numeric)
ggpairs(train.num[,c(3:13)], lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.1)))

M = cor(train.num[,c(3:13)])
corrplot(M)+ theme(axis.text.x = element_text(angle = 45, hjust=1))
```


```{r}
regression_columns <- c('school_type', 'unduplicatedfrpm_eligible_count', 'foster', 'homeless', 'migrantprogram', 'english_learner', 'charter_school', 'nslp_provision_status', 'result.max')

classification_columns <- c('school_type', 'unduplicatedfrpm_eligible_count', 'foster', 'homeless', 'migrantprogram', 'english_learner', 'charter_school', 'nslp_provision_status', 'action_level_exceedance')

train.regression <- train[ , (names(train) %in% regression_columns)]
train.classification <- train[ , (names(train) %in% classification_columns)]

```

      
Initiate a ridge model:
```{r}
#use glmnet to do ridge
school_type_rm <- subset(train, select = -c(school_type.y, calpads_fall_1_certification_status, school_name, county_name, district_name, water_system_name, sample_date, action_level_exceedance, ale_follow_up_action, ale_follow_up_status))

x <- model.matrix(result.max ~ .,school_type_rm)[,-1]
y <- train$result.max
grid <- 10^seq(3, -2, length = 50)
ridge.mod <- glmnet(x, y, alpha = 0, lambda = grid)

coef(ridge.mod)
plot_glmnet(ridge.mod)
```

Run the remainder of the models:
```{r}
n = 6082
set.seed(1)

lm.fit <- lm(result.max ~ ., data=train.regression)
rmse.train = sqrt(mean(lm.fit$residuals^2))
print(lm.fit)
cv1 <- cvFit(lm.fit, data=train.regression, y=train.regression$result.max, K = 10, seed=1)
sprintf("rmse lm.fit %s", cv1)
sprintf("rmse lm.fit %s", rmse.train)

residuals1 <- lm.fit$residuals

cv2 <- cv.glmnet(x, y, alpha = 0)
print(cv2)
plot(cv2)
sprintf("rmse ridge %s", cv2)

lm.fit2 <- lm(result.max ~., data=school_type_rm )
(rmse.train2 = sqrt(mean(lm.fit2$residuals^2)))
cv3 <- cvFit(lm.fit2, data=train.regression, y=train.regression$result.max, K = 10, seed=1)
residuals3 <- lm.fit2$residuals
sprintf("rmse lm.fit2 %s", rmse.train2)
sprintf("rmse cv lm.fit2 %s", cv3)

#we can say that we tried to do this and write about it not working
lm.fit3 <- lm(result.max  ~ . + .:., data = school_type_rm)
rmse.train.4 = sqrt(mean(lm.fit3$residuals^2))
cv4 <- cvFit(lm.fit3, data=school_type_rm, y=school_type_rm$result.max, K = 10, seed=1)
sprintf("rmse lm.fit3 interacctions %s", cv4)
sprintf("rmse lm.fit3 interacctions %s", rmse.train.4)


lm.fit4 <- lm(result.max  ~ . + .:., data = train.regression)
rmse.train.5 = sqrt(mean(lm.fit4$residuals^2))
cv5 <- cvFit(lm.fit4, data=train.regression, y=train.regression$result.max, K = 10, seed=1)
residuals5 <- lm.fit4$residuals
sprintf("rmse lm.fit4 squared transforms %s", cv5)
sprintf("rmse lm.fit4 squared transforms %s", rmse.train.5)

school_type_rm$homeless <- school_type_rm$homeless + .5
school_type_rm$foster <- school_type_rm$foster + .5
school_type_rm$migrantprogram <- school_type_rm$migrantprogram + .5
school_type_rm$english_learner <- school_type_rm$english_learner + .5

lm.fit5 <- lm(log(school_type_rm$result.max) ~ log(school_type_rm$foster) + log(school_type_rm$homeless) +log(school_type_rm$migrantprogram) + log(school_type_rm$english_learner), data=school_type_rm)
rmse.train.6 = sqrt(mean((exp(lm.fit5$residuals))^2))
cv6 <- cvFit(lm.fit5, data=school_type_rm, y=log(school_type_rm$result.max), K = 10, seed=1)
residuals6 <- lm.fit5$residuals
sprintf("rmse lm.fit5 log transforms %s", cv6)
sprintf("rmse lm.fit5 log transforms %s", rmse.train.6)

```

Plot cv RMSE as a function of k:
```{r}
k = c(2:20)
cvk = rep(0, 19)
for (i in 1:19){
  cvk[i]=exp(cvFit(lm.fit5, data=school_type_rm, y=log(school_type_rm$result.max), K = k[i], seed=1)$cv)}

plot(x=k, y=cvk)

```

Plot the residuals
```{r}
model = factor(c(rep("fm1", n), rep("fm3", n), rep("fm5", n),  rep("fm6", n)))
residuals = c(residuals1, residuals3, residuals5, residuals6)
df = data.frame(residuals, model)

ggplot(data = df, aes(x = residuals, color = model)) + geom_density()

model = factor(c(rep("fm1", n), rep("fm3", n), rep("fm5", n),  rep("fm6", n)))
fitted_values = c(lm.fit$fitted.values, lm.fit3$fitted.values, lm.fit4$fitted.values, lm.fit5$fitted.values)
residuals = c(lm.fit$residuals, lm.fit3$residuals, lm.fit4$residuals, lm.fit5$residuals)
df = data.frame(residuals, fitted_values, model)

ggplot(data = df, aes(x = fitted_values, y = residuals, color = model)) + geom_point()

ggplot() + geom_point(aes(x = lm.fit5$residuals, y = lm.fit5$fitted.values))

```

Generate regression tables:
```{r}
all <- stargazer(lm.fit5, title="Selected Prediction Model", align=TRUE, dep.var.labels=c("Maximum Lead (ug/L)"), no.space=TRUE, type = "html")
writeLines(text = all, file("regression_predict.html"))
```


Then, we develop a classification model using logistic regression:
```{r}
school_type_rm <- subset(train, select = -c(school_type.y, calpads_fall_1_certification_status, school_name, county_name, district_name, water_system_name, sample_date, result.max, ale_follow_up_action, ale_follow_up_status))

x <- model.matrix(action_level_exceedance ~ .,school_type_rm)[,-1]
y <- school_type_rm$action_level_exceedance
logistic.mod <- glm(y~x, data= school_type_rm, family = binomial())
summary(logistic.mod)


x <- model.matrix(action_level_exceedance ~ .,train.classification)[,-1]
y <- train.classification$action_level_exceedance
logistic.mod.2 <- glm(y~x, data= train.classification, family = binomial())
summary(logistic.mod.2)

```

We find the model with the best AIC using stepwise addition of covariates:
```{r}
full_model = glm(action_level_exceedance~school_type+unduplicatedfrpm_eligible_count+foster+homeless+migrantprogram+english_learner+charter_school+nslp_provision_status, data= train.classification, family = binomial())
summary(full_model)
null_model = glm(action_level_exceedance ~ 1, family = binomial(), data = train.classification)
summary(null_model)
step(null_model, list(upper = full_model), direction = 'forward')
best_aic_model = glm(action_level_exceedance ~ charter_school + unduplicatedfrpm_eligible_count + 
    english_learner, family = binomial(), data = train.classification)
```

We develop an ROC curve and find the optimal cutoff threshold for positives for both sensitivity and specificity:
```{r}
fitted_model = fitted(best_aic_model)


roc_data = data.frame(fit = fitted_model, obs = train.classification$action_level_exceedance)
my_roc = roc(roc_data$obs ~ roc_data$fit, plot = FALSE)
cat("AUC = ", toString(auc(my_roc)))
options(repr.plot.width=4, repr.plot.height=4)
plot(my_roc)

threshold <- coords(my_roc, "best", ret = "threshold")
```

We plot the accuracy and sensitivity as a funcction of threshold/ cutoff value and develop a confusion matrix: 
```{r}
pred <- prediction(roc_data$fit,roc_data$obs)
acc.perf = performance(pred, measure = "acc")
plot(acc.perf)

tpr.perf = performance(pred, measure = "tpr")
plot(tpr.perf)

threshold2 <- 0.02
table(fitted_model > threshold$threshold, train.classification$action_level_exceedance)
table(fitted_model > threshold2, train.classification$action_level_exceedance)
```

```{r}
all <- stargazer(fitted_model, title="Selected Classification Model", align=TRUE, dep.var.labels=c("Probability of Exceedance"), no.space=TRUE, type = "html")

```

